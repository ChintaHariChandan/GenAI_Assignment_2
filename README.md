# ğŸš€ GenAI_Assignment_2

ğŸ§  **Python implementation of common neural network activation functions with formulas and sample inputs.**

---

## ğŸ“Œ Overview
This repository contains a simple and clear Python implementation of **popular activation functions** used in **Artificial Neural Networks and Deep Learning**.  
Each activation function includes:
- ğŸ“ Mathematical formula (as comments)
- ğŸ§ª Sample input values
- âš™ï¸ NumPy-based implementation

---

## ğŸ”¢ Activation Functions Implemented
âœ” Sigmoid  
âœ” ReLU  
âœ” Leaky ReLU  
âœ” Tanh  
âœ” Softmax  
âœ” ELU  
âœ” Swish  

---

## ğŸ›  Technologies Used
- ğŸ Python  
- ğŸ“¦ NumPy  

---

